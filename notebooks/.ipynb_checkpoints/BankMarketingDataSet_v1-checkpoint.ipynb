{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T00:11:47.963564Z",
     "start_time": "2019-08-11T00:11:47.960561Z"
    }
   },
   "source": [
    "# Initial imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T04:00:37.186475Z",
     "start_time": "2019-08-12T04:00:37.167458Z"
    }
   },
   "outputs": [],
   "source": [
    "# Numeric and data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = None\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "# sklearn\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, FeatureUnion, make_union\n",
    "from sklearn.metrics import make_scorer\n",
    "from scipy.stats import ks_2samp\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from  sklearn.linear_model import Lasso, LassoCV, LogisticRegressionCV\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.feature_selection import SelectFromModel, VarianceThreshold, chi2, SelectKBest\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T14:50:56.837846Z",
     "start_time": "2019-08-11T14:50:56.834853Z"
    }
   },
   "outputs": [],
   "source": [
    "# Global random state for reproducibility\n",
    "random_state_global = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataprep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data from csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Missing Attribute Values: There are several missing values in some categorical attributes, all coded with the \"unknown\" label. These missing values can be treated as a possible class label or using deletion or imputation techniques. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T14:51:00.251199Z",
     "start_time": "2019-08-11T14:51:00.150098Z"
    }
   },
   "outputs": [],
   "source": [
    "df_full = pd.read_csv('../data/bank-additional/bank-additional-full.csv', sep=';', na_values=['unknown'])\n",
    "df_full.columns = df_full.columns.str.replace('.', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T14:51:00.356222Z",
     "start_time": "2019-08-11T14:51:00.340207Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp_var_rate</th>\n",
       "      <th>cons_price_idx</th>\n",
       "      <th>cons_conf_idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr_employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>226</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>307</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital    education default housing loan    contact month  \\\n",
       "0   56  housemaid  married     basic.4y      no      no   no  telephone   may   \n",
       "1   57   services  married  high.school     NaN      no   no  telephone   may   \n",
       "2   37   services  married  high.school      no     yes   no  telephone   may   \n",
       "3   40     admin.  married     basic.6y      no      no   no  telephone   may   \n",
       "4   56   services  married  high.school      no      no  yes  telephone   may   \n",
       "\n",
       "  day_of_week  duration  campaign  pdays  previous     poutcome  emp_var_rate  \\\n",
       "0         mon       261         1    999         0  nonexistent           1.1   \n",
       "1         mon       149         1    999         0  nonexistent           1.1   \n",
       "2         mon       226         1    999         0  nonexistent           1.1   \n",
       "3         mon       151         1    999         0  nonexistent           1.1   \n",
       "4         mon       307         1    999         0  nonexistent           1.1   \n",
       "\n",
       "   cons_price_idx  cons_conf_idx  euribor3m  nr_employed   y  \n",
       "0          93.994          -36.4      4.857       5191.0  no  \n",
       "1          93.994          -36.4      4.857       5191.0  no  \n",
       "2          93.994          -36.4      4.857       5191.0  no  \n",
       "3          93.994          -36.4      4.857       5191.0  no  \n",
       "4          93.994          -36.4      4.857       5191.0  no  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T14:51:00.537454Z",
     "start_time": "2019-08-11T14:51:00.515434Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                  0\n",
       "job                330\n",
       "marital             80\n",
       "education         1731\n",
       "default           8597\n",
       "housing            990\n",
       "loan               990\n",
       "contact              0\n",
       "month                0\n",
       "day_of_week          0\n",
       "duration             0\n",
       "campaign             0\n",
       "pdays                0\n",
       "previous             0\n",
       "poutcome             0\n",
       "emp_var_rate         0\n",
       "cons_price_idx       0\n",
       "cons_conf_idx        0\n",
       "euribor3m            0\n",
       "nr_employed          0\n",
       "y                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Is there missing values on data? YES, I forced it using a_values=['unknown'] using \n",
    "df_full.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T00:30:56.332631Z",
     "start_time": "2019-08-11T00:30:56.330629Z"
    }
   },
   "source": [
    "## Categorical and numeric data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T02:08:22.786742Z",
     "start_time": "2019-08-11T02:08:22.782748Z"
    }
   },
   "source": [
    "## Categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some categorical have a meaningful ordering, like education ('basic.4y' < 'basic.6y',  ...) and default ('yes' > 'no'). For these\n",
    "we will use this information while creating the category data type; for the others, there is no meaningful order, and we will not specify order while creating the category data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T14:51:02.405675Z",
     "start_time": "2019-08-11T14:51:02.339198Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " job\n",
      "admin.           10422\n",
      "blue-collar       9254\n",
      "technician        6743\n",
      "services          3969\n",
      "management        2924\n",
      "retired           1720\n",
      "entrepreneur      1456\n",
      "self-employed     1421\n",
      "housemaid         1060\n",
      "unemployed        1014\n",
      "student            875\n",
      "NaN                330\n",
      "Name: job, dtype: int64\n",
      "\n",
      " marital\n",
      "married     24928\n",
      "single      11568\n",
      "divorced     4612\n",
      "NaN            80\n",
      "Name: marital, dtype: int64\n",
      "\n",
      " education\n",
      "university.degree      12168\n",
      "high.school             9515\n",
      "basic.9y                6045\n",
      "professional.course     5243\n",
      "basic.4y                4176\n",
      "basic.6y                2292\n",
      "NaN                     1731\n",
      "illiterate                18\n",
      "Name: education, dtype: int64\n",
      "\n",
      " default\n",
      "no     32588\n",
      "NaN     8597\n",
      "yes        3\n",
      "Name: default, dtype: int64\n",
      "\n",
      " housing\n",
      "yes    21576\n",
      "no     18622\n",
      "NaN      990\n",
      "Name: housing, dtype: int64\n",
      "\n",
      " loan\n",
      "no     33950\n",
      "yes     6248\n",
      "NaN      990\n",
      "Name: loan, dtype: int64\n",
      "\n",
      " contact\n",
      "cellular     26144\n",
      "telephone    15044\n",
      "Name: contact, dtype: int64\n",
      "\n",
      " month\n",
      "may    13769\n",
      "jul     7174\n",
      "aug     6178\n",
      "jun     5318\n",
      "nov     4101\n",
      "apr     2632\n",
      "oct      718\n",
      "sep      570\n",
      "mar      546\n",
      "dec      182\n",
      "Name: month, dtype: int64\n",
      "\n",
      " day_of_week\n",
      "thu    8623\n",
      "mon    8514\n",
      "wed    8134\n",
      "tue    8090\n",
      "fri    7827\n",
      "Name: day_of_week, dtype: int64\n",
      "\n",
      " poutcome\n",
      "nonexistent    35563\n",
      "failure         4252\n",
      "success         1373\n",
      "Name: poutcome, dtype: int64\n",
      "\n",
      " y\n",
      "no     36548\n",
      "yes     4640\n",
      "Name: y, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Frequency of categories for each categorical feature\n",
    "for col in df_full.select_dtypes('O').columns:\n",
    "    print('\\n', col)\n",
    "    print(df_full[col].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downcasting numeric features to reduce memory usage\n",
    "(inspired on https://www.kaggle.com/gemartin/load-data-reduce-memory-usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T14:51:05.096831Z",
     "start_time": "2019-08-11T14:51:05.064793Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dict storing datatypes of all features\n",
    "dict_dtypes = {}\n",
    "\n",
    "# Categorical features with meaningful ordering\n",
    "dict_dtypes['education'] = CategoricalDtype(categories = ['illiterate', 'basic.4y', 'basic.6y', 'basic.9y', 'high.school', \n",
    "                                                          'professional.course', 'university.degree']\n",
    "                                            , ordered=True)\n",
    "\n",
    "dict_dtypes['default'] = CategoricalDtype(categories = ['no', 'yes'], ordered=True)\n",
    "dict_dtypes['housing'] = CategoricalDtype(categories = ['no', 'yes'], ordered=True)\n",
    "dict_dtypes['loan'] = CategoricalDtype(categories = ['no', 'yes'], ordered=True)\n",
    "dict_dtypes['poutcome'] = CategoricalDtype(categories = ['failure', 'success'], ordered=True)# nonexistent considered as missing value\n",
    "dict_dtypes['y'] = CategoricalDtype(categories = ['no', 'yes'], ordered=True)\n",
    "\n",
    "# Polemic\n",
    "dict_dtypes['day_of_week'] = CategoricalDtype(categories = ['mon', 'tue', 'wed', 'thu', 'fri'], ordered=True)\n",
    "dict_dtypes['month'] = CategoricalDtype(categories = ['jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug',\n",
    "                                                     'sep', 'oct', 'nov', 'dec'], ordered=True)\n",
    "# Other categorical features\n",
    "for col in df_full.select_dtypes('O').columns:\n",
    "    if col not in dict_dtypes.keys():\n",
    "        dict_dtypes[col] = CategoricalDtype(categories = sorted(df_full[col].dropna().unique()), ordered=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T14:51:06.240552Z",
     "start_time": "2019-08-11T14:51:06.155483Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial memory usage: 6.60 MB\n",
      "Memory usage after optimization: 1.49 MB\n",
      "Memory usage decreased by 77.3%\n"
     ]
    }
   ],
   "source": [
    "# Note: pandas alerady have nullable integer datatypes, but I will not use. If a integer column have at least a missing value,\n",
    "# it will be converted to float32.\n",
    "for col in df_full.select_dtypes(np.number):\n",
    "    _vec_min_max = df_full[col].describe()[['min','max']]\n",
    "    _has_null = df_full[col].isnull().max()\n",
    "    _has_float = (df_full[col] % 1 != 0).any()\n",
    "    \n",
    "    if _has_float or _has_null:\n",
    "        dict_dtypes[col] = pd.to_numeric(_vec_min_max, downcast='float').dtype\n",
    "    else:\n",
    "        if _vec_min_max[0] >=0:\n",
    "            dict_dtypes[col] = pd.to_numeric(_vec_min_max, downcast='unsigned').dtype\n",
    "        else:\n",
    "            dict_dtypes[col] = pd.to_numeric(_vec_min_max, downcast='signed').dtype\n",
    "\n",
    "start_memory_usage = df_full.memory_usage().sum() / 1024**2\n",
    "end_memory_usage = df_full.astype(dict_dtypes).memory_usage().sum() / 1024**2\n",
    "\n",
    "print('Initial memory usage: {:.2f} MB'.format(start_memory_usage))\n",
    "print('Memory usage after optimization: {:.2f} MB'.format(end_memory_usage))\n",
    "print('Memory usage decreased by {:.1f}%'.format(100 * (start_memory_usage - end_memory_usage) / start_memory_usage))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying new dtypes inplace on initial dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T14:51:08.760131Z",
     "start_time": "2019-08-11T14:51:08.731104Z"
    }
   },
   "outputs": [],
   "source": [
    "df_full = df_full.astype(dict_dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:09:13.706264Z",
     "start_time": "2019-08-11T05:09:13.702270Z"
    }
   },
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T01:58:46.327480Z",
     "start_time": "2019-08-12T01:58:46.285433Z"
    }
   },
   "outputs": [],
   "source": [
    "# I used pd.get_dummies before splitting instead of including then on pipeline for simplicity\n",
    "X_train, X_test, y_train, y_test = train_test_split(pd.get_dummies(df_full.drop('y', axis=1), dummy_na=True), df_full['y'].cat.codes,\n",
    "                                                    test_size=0.20, random_state=random_state_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T02:01:59.178840Z",
     "start_time": "2019-08-12T02:01:59.172835Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         no\n",
       "1         no\n",
       "2         no\n",
       "3         no\n",
       "4         no\n",
       "        ... \n",
       "41183    yes\n",
       "41184     no\n",
       "41185     no\n",
       "41186    yes\n",
       "41187     no\n",
       "Name: y, Length: 41188, dtype: category\n",
       "Categories (2, object): [no < yes]"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T02:02:09.909920Z",
     "start_time": "2019-08-12T02:02:09.894877Z"
    }
   },
   "outputs": [],
   "source": [
    "num_cols = df_full.select_dtypes(np.number).columns.to_list()\n",
    "cat_cols = df_full.drop(['y'], axis=1).select_dtypes('category').columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T07:11:24.451526Z",
     "start_time": "2019-08-11T07:11:24.448523Z"
    }
   },
   "source": [
    "## KS and gini functions and sklearn scorers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T01:48:39.013861Z",
     "start_time": "2019-08-12T01:48:39.005853Z"
    }
   },
   "outputs": [],
   "source": [
    "def ks_stat(y_true, y_proba):\n",
    "#     As seen on https://medium.com/@xiaowei_6531/using-ks-stat-as-a-model-evaluation-metric-in-scikit-learns-gridsearchcv-33135101601c\n",
    "    return ks_2samp(y_proba[y_true==1], y_proba[y_true!=1]).statistic\n",
    "\n",
    "ks_scorer = make_scorer(ks_stat, needs_proba=True, greater_is_better=True)\n",
    "\n",
    "#Remove redundant calls\n",
    "def ginic(actual, pred):\n",
    "    actual = np.asarray(actual) #In case, someone passes Series or list\n",
    "    n = len(actual)\n",
    "    a_s = actual[np.argsort(pred)]\n",
    "    a_c = a_s.cumsum()\n",
    "    giniSum = a_c.sum() / a_s.sum() - (n + 1) / 2.0\n",
    "    return giniSum / n\n",
    " \n",
    "def gini_normalizedc(a, p):\n",
    "    if p.ndim == 2:#Required for sklearn wrapper\n",
    "        p = p[:,1] #If proba array contains proba for both 0 and 1 classes, just pick class 1\n",
    "    return ginic(a, p) / ginic(a, a)\n",
    "\n",
    "gini_scorer = make_scorer(gini_normalizedc, needs_proba=True, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T06:19:00.014034Z",
     "start_time": "2019-08-11T06:19:00.011041Z"
    }
   },
   "source": [
    "## Basic pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T14:51:31.894158Z",
     "start_time": "2019-08-11T14:51:31.891155Z"
    }
   },
   "outputs": [],
   "source": [
    "# KFold for hyperparameter tuning and acessing model quality\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T14:51:33.080431Z",
     "start_time": "2019-08-11T14:51:33.074425Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_cat_codes(X, return_df=True):\n",
    "    if return_df:\n",
    "        return X.apply(lambda x: x.cat.codes)\n",
    "    else:\n",
    "        return X.apply(lambda x: x.cat.codes).values\n",
    "\n",
    "def from_cat_to_str(X):\n",
    "    return X.astype(str)\n",
    "    \n",
    "def f_select_dtypes(X, dtype):\n",
    "    return X.select_dtypes()\n",
    "\n",
    "select_num_transformer = FunctionTransformer(lambda x: x.select_dtypes(np.number), validate=False)\n",
    "select_cat_transformer = FunctionTransformer(lambda x: x.select_dtypes('category'), validate=False)\n",
    "get_cat_features_transformer = FunctionTransformer(get_cat_codes, validate=False)\n",
    "from_cat_to_str_transformer = FunctionTransformer(from_cat_to_str, validate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T02:07:10.138546Z",
     "start_time": "2019-08-12T02:07:10.133542Z"
    }
   },
   "outputs": [],
   "source": [
    "# If would like to use OneHotEncoder inside pipeline (NOT USED, just for reference!!!)\n",
    "# Using sklearn pipelines\n",
    "linear_model_pipeline = FeatureUnion([\n",
    "    ('num_feat', make_pipeline(select_num_transformer ,StandardScaler())),\n",
    "    ('cat_feat', make_pipeline(select_cat_transformer ,get_cat_features_transformer, OneHotEncoder(sparse=False, handle_unknown='ignore', categories='auto')))\n",
    "     ])\n",
    "\n",
    "# Using DataFrameMapper from sklearn_pandas (Using OneHotEncoder instead of pd.get_dummies)\n",
    "# TODO: remove x0 on feature encoded on OneHotEncoder\n",
    "mapper = DataFrameMapper(\n",
    "    [([col], StandardScaler()) for col in num_cols] + \n",
    "    [([col], [get_cat_features_transformer, OneHotEncoder(dtype=np.int8, sparse=False, handle_unknown='ignore', categories='auto')]) for col in cat_cols]\n",
    "     , input_df=True, df_out=True)\n",
    "# mapper.fit_transform(df_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T02:09:14.483986Z",
     "start_time": "2019-08-12T02:09:14.444951Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.66930454e-03, -6.31114175e-01, -2.06241614e-01, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  1.00000000e+00],\n",
       "       [-8.64094846e-01, -5.46321353e-01,  5.13675879e-01, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  1.00000000e+00],\n",
       "       [ 1.81900684e+00, -9.43305926e-01,  1.23359337e+00, ...,\n",
       "         1.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       ...,\n",
       "       [-4.80794606e-01, -2.45692259e-01, -5.66200360e-01, ...,\n",
       "         0.00000000e+00,  1.00000000e+00,  0.00000000e+00],\n",
       "       [-1.66930454e-03,  1.43583876e-01, -2.06241614e-01, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  1.00000000e+00],\n",
       "       [-1.05574497e+00,  2.90044203e-01, -2.06241614e-01, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  1.00000000e+00]])"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_pipe_df_mapper = DataFrameMapper(\n",
    "    [([col], StandardScaler()) for col in num_cols]\n",
    "     , input_df=True, df_out=False, default=None)\n",
    "lin_pipe_df_mapper.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T02:36:53.983893Z",
     "start_time": "2019-08-12T02:36:53.979897Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VarianceThreshold(threshold=0.0)"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VarianceThreshold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T02:46:34.846738Z",
     "start_time": "2019-08-12T02:46:34.219304Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=Pipeline(memory=None,\n",
       "                                   steps=[('dataframemapper',\n",
       "                                           DataFrameMapper(default=None,\n",
       "                                                           df_out=False,\n",
       "                                                           features=[(['age'],\n",
       "                                                                      StandardScaler(copy=True,\n",
       "                                                                                     with_mean=True,\n",
       "                                                                                     with_std=True)),\n",
       "                                                                     (['duration'],\n",
       "                                                                      StandardScaler(copy=True,\n",
       "                                                                                     with_mean=True,\n",
       "                                                                                     with_std=True)),\n",
       "                                                                     (['campaign'],\n",
       "                                                                      StandardScaler(copy=True,\n",
       "                                                                                     with_mean=True,\n",
       "                                                                                     with_std=True)),\n",
       "                                                                     (['pdays'],\n",
       "                                                                      StandardS...\n",
       "                                          ('lassocv',\n",
       "                                           LassoCV(alphas=None, copy_X=True,\n",
       "                                                   cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "                                                   eps=0.001,\n",
       "                                                   fit_intercept=True,\n",
       "                                                   max_iter=1500, n_alphas=100,\n",
       "                                                   n_jobs=None, normalize=False,\n",
       "                                                   positive=False,\n",
       "                                                   precompute='auto',\n",
       "                                                   random_state=None,\n",
       "                                                   selection='cyclic',\n",
       "                                                   tol=0.0001,\n",
       "                                                   verbose=False))],\n",
       "                                   verbose=False),\n",
       "                max_features=None, norm_order=1, prefit=False, threshold=None)"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_pipe = SelectFromModel(make_pipeline(linear_dataframe_mapper, VarianceThreshold(0), LassoCV(cv=kf, max_iter=1500)))\n",
    "lasso_pipe.fit(X_train[num_cols], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T03:00:32.642029Z",
     "start_time": "2019-08-12T03:00:32.600992Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.66930454e-03, -6.31114175e-01, -2.06241614e-01, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  1.00000000e+00],\n",
       "       [-8.64094846e-01, -5.46321353e-01,  5.13675879e-01, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  1.00000000e+00],\n",
       "       [ 1.81900684e+00, -9.43305926e-01,  1.23359337e+00, ...,\n",
       "         1.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       ...,\n",
       "       [-4.80794606e-01, -2.45692259e-01, -5.66200360e-01, ...,\n",
       "         0.00000000e+00,  1.00000000e+00,  0.00000000e+00],\n",
       "       [-1.66930454e-03,  1.43583876e-01, -2.06241614e-01, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  1.00000000e+00],\n",
       "       [-1.05574497e+00,  2.90044203e-01, -2.06241614e-01, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  1.00000000e+00]])"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(linear_dataframe_mapper.fit_transform(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T03:39:48.636001Z",
     "start_time": "2019-08-12T03:38:40.024153Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=LogisticRegressionCV(Cs=10, class_weight='balanced',\n",
       "                                               cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "                                               dual=False, fit_intercept=True,\n",
       "                                               intercept_scaling=1.0,\n",
       "                                               l1_ratios=[0, 0.5, 1],\n",
       "                                               max_iter=1000,\n",
       "                                               multi_class='warn', n_jobs=10,\n",
       "                                               penalty='elasticnet',\n",
       "                                               random_state=None, refit=True,\n",
       "                                               scoring=None, solver='saga',\n",
       "                                               tol=0.0001, verbose=0),\n",
       "                max_features=None, norm_order=1, prefit=False, threshold=1e-05)"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_pipe = SelectFromModel(LogisticRegressionCV(cv=kf, max_iter=1000, penalty='elasticnet', solver='saga',\n",
    "                                                  l1_ratios=[0, 0.5, 1],  class_weight='balanced', n_jobs=10), threshold=1e-5)\n",
    "lasso_pipe.fit(linear_dataframe_mapper.fit_transform(X_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T04:12:13.903042Z",
     "start_time": "2019-08-12T04:12:13.879011Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2.27720632e+01, 1.34898023e+02, 8.82023835e+00, 2.42593188e+00,\n",
       "        2.39817213e-03, 2.48189186e+02, 2.12763785e+00, 2.94533736e+01,\n",
       "        2.72112359e+02, 4.30539700e-02, 6.79948732e+00, 4.57872713e-01,\n",
       "        3.05747220e+00, 2.37935310e+01, 6.68697317e+01, 2.13840768e-01,\n",
       "        1.82379370e+00, 2.76232127e+00, 1.89901219e+01, 5.37700465e+01,\n",
       "        2.33712987e+00, 4.95914083e-03, 6.71829826e+01, 8.13035832e+00,\n",
       "        6.75414179e+01, 3.80064968e-01, 2.56573109e+02, 2.53651404e+00,\n",
       "        1.85810550e+00, 2.85690886e-01, 3.01328573e-03, 1.17653917e-01,\n",
       "        2.85690886e-01, 2.60345684e+02, 4.53390092e+02,            nan,\n",
       "                   nan,            nan, 7.18647423e+02, 1.77895148e+02,\n",
       "        2.76751982e+02, 1.95681135e+00, 2.43064024e+01, 2.05290371e+00,\n",
       "        5.15499552e+02, 6.66905826e+02, 4.75014988e+00, 1.62803424e+02,\n",
       "                   nan, 1.01191077e+01, 1.74288844e+00, 4.33983392e-01,\n",
       "        6.60240895e+00, 1.94745344e+00,            nan, 2.76037264e+01,\n",
       "        3.23738075e+03, 1.68023615e+02]),\n",
       " array([1.82397987e-006, 3.47569774e-031, 2.97907749e-003, 1.19342253e-001,\n",
       "        9.60942299e-001, 6.44494253e-056, 1.44663538e-001, 5.72782484e-008,\n",
       "        3.93130221e-061, 8.35623683e-001, 9.11840524e-003, 4.98619845e-001,\n",
       "        8.03666048e-002, 1.07242280e-006, 2.90054419e-016, 6.43773561e-001,\n",
       "        1.76862365e-001, 9.65081139e-002, 1.31396937e-005, 2.25382775e-013,\n",
       "        1.26322108e-001, 9.43858444e-001, 2.47440790e-016, 4.35301435e-003,\n",
       "        2.06307313e-016, 5.37568468e-001, 9.58330476e-058, 1.11240139e-001,\n",
       "        1.72843612e-001, 5.92995238e-001, 9.56223387e-001, 7.31593068e-001,\n",
       "        5.92995238e-001, 1.44266500e-058, 1.31930117e-100,             nan,\n",
       "                    nan,             nan, 2.63496471e-158, 1.39639882e-040,\n",
       "        3.83186286e-062, 1.61854750e-001, 8.21655047e-007, 1.51916212e-001,\n",
       "        4.03350032e-114, 4.70434163e-147, 2.92957426e-002, 2.76163417e-037,\n",
       "                    nan, 1.46740020e-003, 1.86773259e-001, 5.10040804e-001,\n",
       "        1.01840890e-002, 1.62861531e-001,             nan, 1.48891650e-007,\n",
       "        0.00000000e+000, 1.99913998e-038]))"
      ]
     },
     "execution_count": 606,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi2(X_train.drop(num_cols, axis=1), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T04:11:55.270061Z",
     "start_time": "2019-08-12T04:11:55.239033Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32950, 58)"
      ]
     },
     "execution_count": 604,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SelectKBest(chi2, k='all').fit_transform(X_train.drop(num_cols, axis=1), y_train).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sklearn_novo_2]",
   "language": "python",
   "name": "conda-env-sklearn_novo_2-py"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
