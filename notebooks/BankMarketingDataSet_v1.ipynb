{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T00:11:47.963564Z",
     "start_time": "2019-08-11T00:11:47.960561Z"
    }
   },
   "source": [
    "# Initial imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T05:57:52.873111Z",
     "start_time": "2019-08-14T05:57:49.296081Z"
    }
   },
   "outputs": [],
   "source": [
    "# Numeric and data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = None\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "# sklearn\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.linear_model import LogisticRegression, Lasso, LassoCV, LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, FeatureUnion, make_union\n",
    "from sklearn.metrics import make_scorer\n",
    "from scipy.stats import ks_2samp\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, ParameterGrid\n",
    "from sklearn.feature_selection import SelectFromModel, VarianceThreshold, chi2, SelectKBest\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import scikitplot as skplt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T02:00:36.869258Z",
     "start_time": "2019-08-14T02:00:36.865254Z"
    }
   },
   "outputs": [],
   "source": [
    "# Global random state for reproducibility\n",
    "random_state_global = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataprep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data from csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Missing Attribute Values: There are several missing values in some categorical attributes, all coded with the \"unknown\" label. These missing values can be treated as a possible class label or using deletion or imputation techniques. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T02:00:41.038952Z",
     "start_time": "2019-08-14T02:00:40.936859Z"
    }
   },
   "outputs": [],
   "source": [
    "df_full = pd.read_csv('../data/bank-additional/bank-additional-full.csv', sep=';', na_values=['unknown'])\n",
    "df_full.columns = df_full.columns.str.replace('.', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T02:00:42.539436Z",
     "start_time": "2019-08-14T02:00:42.522132Z"
    }
   },
   "outputs": [],
   "source": [
    "df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T02:00:42.782126Z",
     "start_time": "2019-08-14T02:00:42.762106Z"
    }
   },
   "outputs": [],
   "source": [
    "# Is there missing values on data? YES, I forced it using a_values=['unknown'] using \n",
    "df_full.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T00:30:56.332631Z",
     "start_time": "2019-08-11T00:30:56.330629Z"
    }
   },
   "source": [
    "## Categorical and numeric data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T02:08:22.786742Z",
     "start_time": "2019-08-11T02:08:22.782748Z"
    }
   },
   "source": [
    "## Categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some categorical have a meaningful ordering, like education ('basic.4y' < 'basic.6y',  ...) and default ('yes' > 'no'). For these\n",
    "we will use this information while creating the category data type; for the others, there is no meaningful order, and we will not specify order while creating the category data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T02:00:44.091152Z",
     "start_time": "2019-08-14T02:00:44.026102Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Frequency of categories for each categorical feature\n",
    "for col in df_full.select_dtypes('O').columns:\n",
    "    print('\\n', col)\n",
    "    print(df_full[col].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downcasting numeric features to reduce memory usage\n",
    "(inspired on https://www.kaggle.com/gemartin/load-data-reduce-memory-usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T02:00:47.538318Z",
     "start_time": "2019-08-14T02:00:47.505273Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dict storing datatypes of all features\n",
    "dict_dtypes = {}\n",
    "\n",
    "# Categorical features with meaningful ordering\n",
    "dict_dtypes['education'] = CategoricalDtype(categories = ['illiterate', 'basic.4y', 'basic.6y', 'basic.9y', 'high.school', \n",
    "                                                          'professional.course', 'university.degree']\n",
    "                                            , ordered=True)\n",
    "\n",
    "dict_dtypes['default'] = CategoricalDtype(categories = ['no', 'yes'], ordered=True)\n",
    "dict_dtypes['housing'] = CategoricalDtype(categories = ['no', 'yes'], ordered=True)\n",
    "dict_dtypes['loan'] = CategoricalDtype(categories = ['no', 'yes'], ordered=True)\n",
    "dict_dtypes['poutcome'] = CategoricalDtype(categories = ['failure', 'success'], ordered=True)# nonexistent considered as missing value\n",
    "dict_dtypes['y'] = CategoricalDtype(categories = ['no', 'yes'], ordered=True)\n",
    "\n",
    "# Polemic\n",
    "dict_dtypes['day_of_week'] = CategoricalDtype(categories = ['mon', 'tue', 'wed', 'thu', 'fri'], ordered=True)\n",
    "dict_dtypes['month'] = CategoricalDtype(categories = ['jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug',\n",
    "                                                     'sep', 'oct', 'nov', 'dec'], ordered=True)\n",
    "# Other categorical features\n",
    "for col in df_full.select_dtypes('O').columns:\n",
    "    if col not in dict_dtypes.keys():\n",
    "        dict_dtypes[col] = CategoricalDtype(categories = sorted(df_full[col].dropna().unique()), ordered=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T02:00:49.058605Z",
     "start_time": "2019-08-14T02:00:48.969526Z"
    }
   },
   "outputs": [],
   "source": [
    "# Note: pandas alerady have nullable integer datatypes, but I will not use. If a integer column have at least a missing value,\n",
    "# it will be converted to float32.\n",
    "for col in df_full.select_dtypes(np.number):\n",
    "    _vec_min_max = df_full[col].describe()[['min','max']]\n",
    "    _has_null = df_full[col].isnull().max()\n",
    "    _has_float = (df_full[col] % 1 != 0).any()\n",
    "    \n",
    "    if _has_float or _has_null:\n",
    "        dict_dtypes[col] = pd.to_numeric(_vec_min_max, downcast='float').dtype\n",
    "    else:\n",
    "        if _vec_min_max[0] >=0:\n",
    "            dict_dtypes[col] = pd.to_numeric(_vec_min_max, downcast='unsigned').dtype\n",
    "        else:\n",
    "            dict_dtypes[col] = pd.to_numeric(_vec_min_max, downcast='signed').dtype\n",
    "\n",
    "start_memory_usage = df_full.memory_usage().sum() / 1024**2\n",
    "end_memory_usage = df_full.astype(dict_dtypes).memory_usage().sum() / 1024**2\n",
    "\n",
    "print('Initial memory usage: {:.2f} MB'.format(start_memory_usage))\n",
    "print('Memory usage after optimization: {:.2f} MB'.format(end_memory_usage))\n",
    "print('Memory usage decreased by {:.1f}%'.format(100 * (start_memory_usage - end_memory_usage) / start_memory_usage))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying new dtypes inplace on initial dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T02:00:51.285316Z",
     "start_time": "2019-08-14T02:00:51.257292Z"
    }
   },
   "outputs": [],
   "source": [
    "df_full = df_full.astype(dict_dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T05:09:13.706264Z",
     "start_time": "2019-08-11T05:09:13.702270Z"
    }
   },
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T04:37:14.997074Z",
     "start_time": "2019-08-14T04:37:14.979042Z"
    }
   },
   "outputs": [],
   "source": [
    "# I used pd.get_dummies before splitting instead of including then on pipeline for simplicity\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_full.drop('y', axis=1), df_full['y'].cat.codes,\n",
    "                                                    test_size=0.20, random_state=random_state_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T04:37:16.016197Z",
     "start_time": "2019-08-14T04:37:16.002184Z"
    }
   },
   "outputs": [],
   "source": [
    "num_cols = df_full.select_dtypes(np.number).columns.to_list()\n",
    "cat_cols = df_full.drop(['y'], axis=1).select_dtypes('category').columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T07:11:24.451526Z",
     "start_time": "2019-08-11T07:11:24.448523Z"
    }
   },
   "source": [
    "## KS and gini functions and sklearn scorers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T02:00:55.048816Z",
     "start_time": "2019-08-14T02:00:55.040799Z"
    }
   },
   "outputs": [],
   "source": [
    "def ks_stat(y_true, y_proba):\n",
    "#     As seen on https://medium.com/@xiaowei_6531/using-ks-stat-as-a-model-evaluation-metric-in-scikit-learns-gridsearchcv-33135101601c\n",
    "    return ks_2samp(y_proba[y_true==1], y_proba[y_true!=1]).statistic\n",
    "\n",
    "ks_scorer = make_scorer(ks_stat, needs_proba=True, greater_is_better=True)\n",
    "\n",
    "#Remove redundant calls\n",
    "def ginic(actual, pred):\n",
    "    actual = np.asarray(actual) #In case, someone passes Series or list\n",
    "    n = len(actual)\n",
    "    a_s = actual[np.argsort(pred)]\n",
    "    a_c = a_s.cumsum()\n",
    "    giniSum = a_c.sum() / a_s.sum() - (n + 1) / 2.0\n",
    "    return giniSum / n\n",
    " \n",
    "def gini_normalizedc(a, p):\n",
    "    if p.ndim == 2:#Required for sklearn wrapper\n",
    "        p = p[:,1] #If proba array contains proba for both 0 and 1 classes, just pick class 1\n",
    "    return ginic(a, p) / ginic(a, a)\n",
    "\n",
    "gini_scorer = make_scorer(gini_normalizedc, needs_proba=True, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T06:19:00.014034Z",
     "start_time": "2019-08-11T06:19:00.011041Z"
    }
   },
   "source": [
    "## Basic pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T02:00:56.325059Z",
     "start_time": "2019-08-14T02:00:56.321047Z"
    }
   },
   "outputs": [],
   "source": [
    "# KFold for hyperparameter tuning and acessing model quality\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T04:58:33.080956Z",
     "start_time": "2019-08-14T04:58:33.072948Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_cat_codes(X, return_df=True):\n",
    "    if return_df:\n",
    "        return X.apply(lambda x: x.cat.codes)\n",
    "    else:\n",
    "        return X.apply(lambda x: x.cat.codes).values\n",
    "\n",
    "def from_cat_to_str(X):\n",
    "    return X.astype(str)\n",
    "    \n",
    "def f_select_dtypes(X, dtype):\n",
    "    return X.select_dtypes()\n",
    "\n",
    "select_num_transformer = FunctionTransformer(lambda x: x.select_dtypes(np.number), validate=False)\n",
    "select_cat_transformer = FunctionTransformer(lambda x: x.select_dtypes('category'), validate=False)\n",
    "get_cat_codes_transformer = FunctionTransformer(get_cat_codes, validate=False)\n",
    "from_cat_to_str_transformer = FunctionTransformer(from_cat_to_str, validate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T02:00:59.184107Z",
     "start_time": "2019-08-14T02:00:59.177102Z"
    }
   },
   "outputs": [],
   "source": [
    "# If would like to use OneHotEncoder inside pipeline (NOT USED, just for reference!!!)\n",
    "# Using sklearn pipelines\n",
    "linear_model_pipeline = FeatureUnion([\n",
    "    ('num_feat', make_pipeline(select_num_transformer ,StandardScaler())),\n",
    "    ('cat_feat', make_pipeline(select_cat_transformer ,get_cat_features_transformer, OneHotEncoder(sparse=False, handle_unknown='ignore', categories='auto')))\n",
    "     ])\n",
    "\n",
    "# Using DataFrameMapper from sklearn_pandas (Using OneHotEncoder instead of pd.get_dummies)\n",
    "# TODO: remove x0 on feature encoded on OneHotEncoder\n",
    "mapper = DataFrameMapper(\n",
    "    [([col], StandardScaler()) for col in num_cols] + \n",
    "    [([col], [get_cat_features_transformer, OneHotEncoder(dtype=np.int8, sparse=False, handle_unknown='ignore', categories='auto')]) for col in cat_cols]\n",
    "     , input_df=True, df_out=True)\n",
    "# mapper.fit_transform(df_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T02:01:34.187120Z",
     "start_time": "2019-08-14T02:01:34.185127Z"
    }
   },
   "source": [
    "# Metrics for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T05:01:02.207682Z",
     "start_time": "2019-08-14T05:01:02.201678Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generic Pipeline\n",
    "num_pipe = Pipeline(steps=[('scaler', None)])\n",
    "cat_pipe = Pipeline(steps=[('cat_imputer', SimpleImputer(strategy='constant', fill_value='cat_missing')),\n",
    "                           ('cat_encoder_1', None), ('cat_encoder_2', None)])\n",
    "\n",
    "feat_pipe = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', cat_pipe, cat_cols),\n",
    "        ('num', num_pipe, num_cols)])\n",
    "\n",
    "clf = Pipeline(steps=[('feat_pipe', feat_pipe),\n",
    "                      ('classifier', None)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T05:44:49.549647Z",
     "start_time": "2019-08-14T05:42:18.392779Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV] classifier=LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=1000, multi_class='warn', n_jobs=10,\n",
      "                   penalty='elasticnet', random_state=42, solver='saga',\n",
      "                   tol=0.0001, verbose=0, warm_start=False), classifier__l1_ratio=0, feat_pipe__cat__cat_encoder_1=FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
      "                    func=<function from_cat_to_str at 0x000001E59BA580D8>,\n",
      "                    inv_kw_args=None, inverse_func=None, kw_args=None,\n",
      "                    pass_y='deprecated', validate=False), feat_pipe__cat__cat_encoder_2=OneHotEncoder(categorical_features=None, categories='auto', drop=None,\n",
      "              dtype=<class 'numpy.uint8'>, handle_unknown='ignore',\n",
      "              n_values=None, sparse=False), feat_pipe__num__scaler=StandardScaler(copy=True, with_mean=True, with_std=True) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier=LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=1000, multi_class='warn', n_jobs=10,\n",
      "                   penalty='elasticnet', random_state=42, solver='saga',\n",
      "                   tol=0.0001, verbose=0, warm_start=False), classifier__l1_ratio=0, feat_pipe__cat__cat_encoder_1=FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
      "                    func=<function from_cat_to_str at 0x000001E59BA580D8>,\n",
      "                    inv_kw_args=None, inverse_func=None, kw_args=None,\n",
      "                    pass_y='deprecated', validate=False), feat_pipe__cat__cat_encoder_2=OneHotEncoder(categorical_features=None, categories='auto', drop=None,\n",
      "              dtype=<class 'numpy.uint8'>, handle_unknown='ignore',\n",
      "              n_values=None, sparse=False), feat_pipe__num__scaler=StandardScaler(copy=True, with_mean=True, with_std=True), total=   5.0s\n",
      "[CV] classifier=LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=0,\n",
      "                   max_iter=1000, multi_class='warn', n_jobs=10,\n",
      "                   penalty='elasticnet', random_state=42, solver='saga',\n",
      "                   tol=0.0001, verbose=0, warm_start=False), classifier__l1_ratio=0, feat_pipe__cat__cat_encoder_1=FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
      "                    func=<function from_cat_to_str at 0x000001E59BA580D8>,\n",
      "                    inv_kw_args=None, inverse_func=None, kw_args=None,\n",
      "                    pass_y='deprecated', validate=False), feat_pipe__cat__cat_encoder_2=OneHotEncoder(categorical_features=None, categories='auto', drop=None,\n",
      "              dtype=<class 'numpy.uint8'>, handle_unknown='ignore',\n",
      "              n_values=None, sparse=False), feat_pipe__num__scaler=StandardScaler(copy=True, with_mean=True, with_std=True) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier=LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=0,\n",
      "                   max_iter=1000, multi_class='warn', n_jobs=10,\n",
      "                   penalty='elasticnet', random_state=42, solver='saga',\n",
      "                   tol=0.0001, verbose=0, warm_start=False), classifier__l1_ratio=0, feat_pipe__cat__cat_encoder_1=FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
      "                    func=<function from_cat_to_str at 0x000001E59BA580D8>,\n",
      "                    inv_kw_args=None, inverse_func=None, kw_args=None,\n",
      "                    pass_y='deprecated', validate=False), feat_pipe__cat__cat_encoder_2=OneHotEncoder(categorical_features=None, categories='auto', drop=None,\n",
      "              dtype=<class 'numpy.uint8'>, handle_unknown='ignore',\n",
      "              n_values=None, sparse=False), feat_pipe__num__scaler=StandardScaler(copy=True, with_mean=True, with_std=True), total=   6.4s\n",
      "[CV] classifier=LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=0,\n",
      "                   max_iter=1000, multi_class='warn', n_jobs=10,\n",
      "                   penalty='elasticnet', random_state=42, solver='saga',\n",
      "                   tol=0.0001, verbose=0, warm_start=False), classifier__l1_ratio=0, feat_pipe__cat__cat_encoder_1=FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
      "                    func=<function from_cat_to_str at 0x000001E59BA580D8>,\n",
      "                    inv_kw_args=None, inverse_func=None, kw_args=None,\n",
      "                    pass_y='deprecated', validate=False), feat_pipe__cat__cat_encoder_2=OneHotEncoder(categorical_features=None, categories='auto', drop=None,\n",
      "              dtype=<class 'numpy.uint8'>, handle_unknown='ignore',\n",
      "              n_values=None, sparse=False), feat_pipe__num__scaler=StandardScaler(copy=True, with_mean=True, with_std=True) \n",
      "[CV]  classifier=LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=0,\n",
      "                   max_iter=1000, multi_class='warn', n_jobs=10,\n",
      "                   penalty='elasticnet', random_state=42, solver='saga',\n",
      "                   tol=0.0001, verbose=0, warm_start=False), classifier__l1_ratio=0, feat_pipe__cat__cat_encoder_1=FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
      "                    func=<function from_cat_to_str at 0x000001E59BA580D8>,\n",
      "                    inv_kw_args=None, inverse_func=None, kw_args=None,\n",
      "                    pass_y='deprecated', validate=False), feat_pipe__cat__cat_encoder_2=OneHotEncoder(categorical_features=None, categories='auto', drop=None,\n",
      "              dtype=<class 'numpy.uint8'>, handle_unknown='ignore',\n",
      "              n_values=None, sparse=False), feat_pipe__num__scaler=StandardScaler(copy=True, with_mean=True, with_std=True), total=   5.5s\n",
      "[CV] classifier=LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=0,\n",
      "                   max_iter=1000, multi_class='warn', n_jobs=10,\n",
      "                   penalty='elasticnet', random_state=42, solver='saga',\n",
      "                   tol=0.0001, verbose=0, warm_start=False), classifier__l1_ratio=0, feat_pipe__cat__cat_encoder_1=FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
      "                    func=<function from_cat_to_str at 0x000001E59BA580D8>,\n",
      "                    inv_kw_args=None, inverse_func=None, kw_args=None,\n",
      "                    pass_y='deprecated', validate=False), feat_pipe__cat__cat_encoder_2=OneHotEncoder(categorical_features=None, categories='auto', drop=None,\n",
      "              dtype=<class 'numpy.uint8'>, handle_unknown='ignore',\n",
      "              n_values=None, sparse=False), feat_pipe__num__scaler=StandardScaler(copy=True, with_mean=True, with_std=True) \n",
      "[CV]  classifier=LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=0,\n",
      "                   max_iter=1000, multi_class='warn', n_jobs=10,\n",
      "                   penalty='elasticnet', random_state=42, solver='saga',\n",
      "                   tol=0.0001, verbose=0, warm_start=False), classifier__l1_ratio=0, feat_pipe__cat__cat_encoder_1=FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
      "                    func=<function from_cat_to_str at 0x000001E59BA580D8>,\n",
      "                    inv_kw_args=None, inverse_func=None, kw_args=None,\n",
      "                    pass_y='deprecated', validate=False), feat_pipe__cat__cat_encoder_2=OneHotEncoder(categorical_features=None, categories='auto', drop=None,\n",
      "              dtype=<class 'numpy.uint8'>, handle_unknown='ignore',\n",
      "              n_values=None, sparse=False), feat_pipe__num__scaler=StandardScaler(copy=True, with_mean=True, with_std=True), total=   5.3s\n",
      "[CV] classifier=LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=0,\n",
      "                   max_iter=1000, multi_class='warn', n_jobs=10,\n",
      "                   penalty='elasticnet', random_state=42, solver='saga',\n",
      "                   tol=0.0001, verbose=0, warm_start=False), classifier__l1_ratio=0, feat_pipe__cat__cat_encoder_1=FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
      "                    func=<function from_cat_to_str at 0x000001E59BA580D8>,\n",
      "                    inv_kw_args=None, inverse_func=None, kw_args=None,\n",
      "                    pass_y='deprecated', validate=False), feat_pipe__cat__cat_encoder_2=OneHotEncoder(categorical_features=None, categories='auto', drop=None,\n",
      "              dtype=<class 'numpy.uint8'>, handle_unknown='ignore',\n",
      "              n_values=None, sparse=False), feat_pipe__num__scaler=StandardScaler(copy=True, with_mean=True, with_std=True) \n",
      "[CV]  classifier=LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=0,\n",
      "                   max_iter=1000, multi_class='warn', n_jobs=10,\n",
      "                   penalty='elasticnet', random_state=42, solver='saga',\n",
      "                   tol=0.0001, verbose=0, warm_start=False), classifier__l1_ratio=0, feat_pipe__cat__cat_encoder_1=FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
      "                    func=<function from_cat_to_str at 0x000001E59BA580D8>,\n",
      "                    inv_kw_args=None, inverse_func=None, kw_args=None,\n",
      "                    pass_y='deprecated', validate=False), feat_pipe__cat__cat_encoder_2=OneHotEncoder(categorical_features=None, categories='auto', drop=None,\n",
      "              dtype=<class 'numpy.uint8'>, handle_unknown='ignore',\n",
      "              n_values=None, sparse=False), feat_pipe__num__scaler=StandardScaler(copy=True, with_mean=True, with_std=True), total=   5.2s\n",
      "[CV] classifier=LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=0,\n",
      "                   max_iter=1000, multi_class='warn', n_jobs=10,\n",
      "                   penalty='elasticnet', random_state=42, solver='saga',\n",
      "                   tol=0.0001, verbose=0, warm_start=False), classifier__l1_ratio=0.5, feat_pipe__cat__cat_encoder_1=FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
      "                    func=<function from_cat_to_str at 0x000001E59BA580D8>,\n",
      "                    inv_kw_args=None, inverse_func=None, kw_args=None,\n",
      "                    pass_y='deprecated', validate=False), feat_pipe__cat__cat_encoder_2=OneHotEncoder(categorical_features=None, categories='auto', drop=None,\n",
      "              dtype=<class 'numpy.uint8'>, handle_unknown='ignore',\n",
      "              n_values=None, sparse=False), feat_pipe__num__scaler=StandardScaler(copy=True, with_mean=True, with_std=True) \n",
      "[CV]  classifier=LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=0,\n",
      "                   max_iter=1000, multi_class='warn', n_jobs=10,\n",
      "                   penalty='elasticnet', random_state=42, solver='saga',\n",
      "                   tol=0.0001, verbose=0, warm_start=False), classifier__l1_ratio=0.5, feat_pipe__cat__cat_encoder_1=FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
      "                    func=<function from_cat_to_str at 0x000001E59BA580D8>,\n",
      "                    inv_kw_args=None, inverse_func=None, kw_args=None,\n",
      "                    pass_y='deprecated', validate=False), feat_pipe__cat__cat_encoder_2=OneHotEncoder(categorical_features=None, categories='auto', drop=None,\n",
      "              dtype=<class 'numpy.uint8'>, handle_unknown='ignore',\n",
      "              n_values=None, sparse=False), feat_pipe__num__scaler=StandardScaler(copy=True, with_mean=True, with_std=True), total=  13.8s\n",
      "[CV] classifier=LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=0.5,\n",
      "                   max_iter=1000, multi_class='warn', n_jobs=10,\n",
      "                   penalty='elasticnet', random_state=42, solver='saga',\n",
      "                   tol=0.0001, verbose=0, warm_start=False), classifier__l1_ratio=0.5, feat_pipe__cat__cat_encoder_1=FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
      "                    func=<function from_cat_to_str at 0x000001E59BA580D8>,\n",
      "                    inv_kw_args=None, inverse_func=None, kw_args=None,\n",
      "                    pass_y='deprecated', validate=False), feat_pipe__cat__cat_encoder_2=OneHotEncoder(categorical_features=None, categories='auto', drop=None,\n",
      "              dtype=<class 'numpy.uint8'>, handle_unknown='ignore',\n",
      "              n_values=None, sparse=False), feat_pipe__num__scaler=StandardScaler(copy=True, with_mean=True, with_std=True) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier=LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=0.5,\n",
      "                   max_iter=1000, multi_class='warn', n_jobs=10,\n",
      "                   penalty='elasticnet', random_state=42, solver='saga',\n",
      "                   tol=0.0001, verbose=0, warm_start=False), classifier__l1_ratio=0.5, feat_pipe__cat__cat_encoder_1=FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
      "                    func=<function from_cat_to_str at 0x000001E59BA580D8>,\n",
      "                    inv_kw_args=None, inverse_func=None, kw_args=None,\n",
      "                    pass_y='deprecated', validate=False), feat_pipe__cat__cat_encoder_2=OneHotEncoder(categorical_features=None, categories='auto', drop=None,\n",
      "              dtype=<class 'numpy.uint8'>, handle_unknown='ignore',\n",
      "              n_values=None, sparse=False), feat_pipe__num__scaler=StandardScaler(copy=True, with_mean=True, with_std=True), total=  13.8s\n",
      "[CV] classifier=LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=0.5,\n",
      "                   max_iter=1000, multi_class='warn', n_jobs=10,\n",
      "                   penalty='elasticnet', random_state=42, solver='saga',\n",
      "                   tol=0.0001, verbose=0, warm_start=False), classifier__l1_ratio=0.5, feat_pipe__cat__cat_encoder_1=FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
      "                    func=<function from_cat_to_str at 0x000001E59BA580D8>,\n",
      "                    inv_kw_args=None, inverse_func=None, kw_args=None,\n",
      "                    pass_y='deprecated', validate=False), feat_pipe__cat__cat_encoder_2=OneHotEncoder(categorical_features=None, categories='auto', drop=None,\n",
      "              dtype=<class 'numpy.uint8'>, handle_unknown='ignore',\n",
      "              n_values=None, sparse=False), feat_pipe__num__scaler=StandardScaler(copy=True, with_mean=True, with_std=True) \n",
      "[CV]  classifier=LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=0.5,\n",
      "                   max_iter=1000, multi_class='warn', n_jobs=10,\n",
      "                   penalty='elasticnet', random_state=42, solver='saga',\n",
      "                   tol=0.0001, verbose=0, warm_start=False), classifier__l1_ratio=0.5, feat_pipe__cat__cat_encoder_1=FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
      "                    func=<function from_cat_to_str at 0x000001E59BA580D8>,\n",
      "                    inv_kw_args=None, inverse_func=None, kw_args=None,\n",
      "                    pass_y='deprecated', validate=False), feat_pipe__cat__cat_encoder_2=OneHotEncoder(categorical_features=None, categories='auto', drop=None,\n",
      "              dtype=<class 'numpy.uint8'>, handle_unknown='ignore',\n",
      "              n_values=None, sparse=False), feat_pipe__num__scaler=StandardScaler(copy=True, with_mean=True, with_std=True), total=  10.1s\n",
      "[CV] classifier=LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=0.5,\n",
      "                   max_iter=1000, multi_class='warn', n_jobs=10,\n",
      "                   penalty='elasticnet', random_state=42, solver='saga',\n",
      "                   tol=0.0001, verbose=0, warm_start=False), classifier__l1_ratio=0.5, feat_pipe__cat__cat_encoder_1=FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
      "                    func=<function from_cat_to_str at 0x000001E59BA580D8>,\n",
      "                    inv_kw_args=None, inverse_func=None, kw_args=None,\n",
      "                    pass_y='deprecated', validate=False), feat_pipe__cat__cat_encoder_2=OneHotEncoder(categorical_features=None, categories='auto', drop=None,\n",
      "              dtype=<class 'numpy.uint8'>, handle_unknown='ignore',\n",
      "              n_values=None, sparse=False), feat_pipe__num__scaler=StandardScaler(copy=True, with_mean=True, with_std=True) \n",
      "[CV]  classifier=LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=0.5,\n",
      "                   max_iter=1000, multi_class='warn', n_jobs=10,\n",
      "                   penalty='elasticnet', random_state=42, solver='saga',\n",
      "                   tol=0.0001, verbose=0, warm_start=False), classifier__l1_ratio=0.5, feat_pipe__cat__cat_encoder_1=FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
      "                    func=<function from_cat_to_str at 0x000001E59BA580D8>,\n",
      "                    inv_kw_args=None, inverse_func=None, kw_args=None,\n",
      "                    pass_y='deprecated', validate=False), feat_pipe__cat__cat_encoder_2=OneHotEncoder(categorical_features=None, categories='auto', drop=None,\n",
      "              dtype=<class 'numpy.uint8'>, handle_unknown='ignore',\n",
      "              n_values=None, sparse=False), feat_pipe__num__scaler=StandardScaler(copy=True, with_mean=True, with_std=True), total=  13.2s\n",
      "[CV] classifier=LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=0.5,\n",
      "                   max_iter=1000, multi_class='warn', n_jobs=10,\n",
      "                   penalty='elasticnet', random_state=42, solver='saga',\n",
      "                   tol=0.0001, verbose=0, warm_start=False), classifier__l1_ratio=0.5, feat_pipe__cat__cat_encoder_1=FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
      "                    func=<function from_cat_to_str at 0x000001E59BA580D8>,\n",
      "                    inv_kw_args=None, inverse_func=None, kw_args=None,\n",
      "                    pass_y='deprecated', validate=False), feat_pipe__cat__cat_encoder_2=OneHotEncoder(categorical_features=None, categories='auto', drop=None,\n",
      "              dtype=<class 'numpy.uint8'>, handle_unknown='ignore',\n",
      "              n_values=None, sparse=False), feat_pipe__num__scaler=StandardScaler(copy=True, with_mean=True, with_std=True) \n",
      "[CV]  classifier=LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=0.5,\n",
      "                   max_iter=1000, multi_class='warn', n_jobs=10,\n",
      "                   penalty='elasticnet', random_state=42, solver='saga',\n",
      "                   tol=0.0001, verbose=0, warm_start=False), classifier__l1_ratio=0.5, feat_pipe__cat__cat_encoder_1=FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
      "                    func=<function from_cat_to_str at 0x000001E59BA580D8>,\n",
      "                    inv_kw_args=None, inverse_func=None, kw_args=None,\n",
      "                    pass_y='deprecated', validate=False), feat_pipe__cat__cat_encoder_2=OneHotEncoder(categorical_features=None, categories='auto', drop=None,\n",
      "              dtype=<class 'numpy.uint8'>, handle_unknown='ignore',\n",
      "              n_values=None, sparse=False), feat_pipe__num__scaler=StandardScaler(copy=True, with_mean=True, with_std=True), total=  18.4s\n",
      "[CV] classifier=LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=0.5,\n",
      "                   max_iter=1000, multi_class='warn', n_jobs=10,\n",
      "                   penalty='elasticnet', random_state=42, solver='saga',\n",
      "                   tol=0.0001, verbose=0, warm_start=False), classifier__l1_ratio=1, feat_pipe__cat__cat_encoder_1=FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
      "                    func=<function from_cat_to_str at 0x000001E59BA580D8>,\n",
      "                    inv_kw_args=None, inverse_func=None, kw_args=None,\n",
      "                    pass_y='deprecated', validate=False), feat_pipe__cat__cat_encoder_2=OneHotEncoder(categorical_features=None, categories='auto', drop=None,\n",
      "              dtype=<class 'numpy.uint8'>, handle_unknown='ignore',\n",
      "              n_values=None, sparse=False), feat_pipe__num__scaler=StandardScaler(copy=True, with_mean=True, with_std=True) \n",
      "[CV]  classifier=LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=0.5,\n",
      "                   max_iter=1000, multi_class='warn', n_jobs=10,\n",
      "                   penalty='elasticnet', random_state=42, solver='saga',\n",
      "                   tol=0.0001, verbose=0, warm_start=False), classifier__l1_ratio=1, feat_pipe__cat__cat_encoder_1=FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
      "                    func=<function from_cat_to_str at 0x000001E59BA580D8>,\n",
      "                    inv_kw_args=None, inverse_func=None, kw_args=None,\n",
      "                    pass_y='deprecated', validate=False), feat_pipe__cat__cat_encoder_2=OneHotEncoder(categorical_features=None, categories='auto', drop=None,\n",
      "              dtype=<class 'numpy.uint8'>, handle_unknown='ignore',\n",
      "              n_values=None, sparse=False), feat_pipe__num__scaler=StandardScaler(copy=True, with_mean=True, with_std=True), total=   6.2s\n",
      "[CV] classifier=LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=1,\n",
      "                   max_iter=1000, multi_class='warn', n_jobs=10,\n",
      "                   penalty='elasticnet', random_state=42, solver='saga',\n",
      "                   tol=0.0001, verbose=0, warm_start=False), classifier__l1_ratio=1, feat_pipe__cat__cat_encoder_1=FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
      "                    func=<function from_cat_to_str at 0x000001E59BA580D8>,\n",
      "                    inv_kw_args=None, inverse_func=None, kw_args=None,\n",
      "                    pass_y='deprecated', validate=False), feat_pipe__cat__cat_encoder_2=OneHotEncoder(categorical_features=None, categories='auto', drop=None,\n",
      "              dtype=<class 'numpy.uint8'>, handle_unknown='ignore',\n",
      "              n_values=None, sparse=False), feat_pipe__num__scaler=StandardScaler(copy=True, with_mean=True, with_std=True) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  classifier=LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=1,\n",
      "                   max_iter=1000, multi_class='warn', n_jobs=10,\n",
      "                   penalty='elasticnet', random_state=42, solver='saga',\n",
      "                   tol=0.0001, verbose=0, warm_start=False), classifier__l1_ratio=1, feat_pipe__cat__cat_encoder_1=FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
      "                    func=<function from_cat_to_str at 0x000001E59BA580D8>,\n",
      "                    inv_kw_args=None, inverse_func=None, kw_args=None,\n",
      "                    pass_y='deprecated', validate=False), feat_pipe__cat__cat_encoder_2=OneHotEncoder(categorical_features=None, categories='auto', drop=None,\n",
      "              dtype=<class 'numpy.uint8'>, handle_unknown='ignore',\n",
      "              n_values=None, sparse=False), feat_pipe__num__scaler=StandardScaler(copy=True, with_mean=True, with_std=True), total=  11.1s\n",
      "[CV] classifier=LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=1,\n",
      "                   max_iter=1000, multi_class='warn', n_jobs=10,\n",
      "                   penalty='elasticnet', random_state=42, solver='saga',\n",
      "                   tol=0.0001, verbose=0, warm_start=False), classifier__l1_ratio=1, feat_pipe__cat__cat_encoder_1=FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
      "                    func=<function from_cat_to_str at 0x000001E59BA580D8>,\n",
      "                    inv_kw_args=None, inverse_func=None, kw_args=None,\n",
      "                    pass_y='deprecated', validate=False), feat_pipe__cat__cat_encoder_2=OneHotEncoder(categorical_features=None, categories='auto', drop=None,\n",
      "              dtype=<class 'numpy.uint8'>, handle_unknown='ignore',\n",
      "              n_values=None, sparse=False), feat_pipe__num__scaler=StandardScaler(copy=True, with_mean=True, with_std=True) \n",
      "[CV]  classifier=LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=1,\n",
      "                   max_iter=1000, multi_class='warn', n_jobs=10,\n",
      "                   penalty='elasticnet', random_state=42, solver='saga',\n",
      "                   tol=0.0001, verbose=0, warm_start=False), classifier__l1_ratio=1, feat_pipe__cat__cat_encoder_1=FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
      "                    func=<function from_cat_to_str at 0x000001E59BA580D8>,\n",
      "                    inv_kw_args=None, inverse_func=None, kw_args=None,\n",
      "                    pass_y='deprecated', validate=False), feat_pipe__cat__cat_encoder_2=OneHotEncoder(categorical_features=None, categories='auto', drop=None,\n",
      "              dtype=<class 'numpy.uint8'>, handle_unknown='ignore',\n",
      "              n_values=None, sparse=False), feat_pipe__num__scaler=StandardScaler(copy=True, with_mean=True, with_std=True), total=   7.0s\n",
      "[CV] classifier=LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=1,\n",
      "                   max_iter=1000, multi_class='warn', n_jobs=10,\n",
      "                   penalty='elasticnet', random_state=42, solver='saga',\n",
      "                   tol=0.0001, verbose=0, warm_start=False), classifier__l1_ratio=1, feat_pipe__cat__cat_encoder_1=FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
      "                    func=<function from_cat_to_str at 0x000001E59BA580D8>,\n",
      "                    inv_kw_args=None, inverse_func=None, kw_args=None,\n",
      "                    pass_y='deprecated', validate=False), feat_pipe__cat__cat_encoder_2=OneHotEncoder(categorical_features=None, categories='auto', drop=None,\n",
      "              dtype=<class 'numpy.uint8'>, handle_unknown='ignore',\n",
      "              n_values=None, sparse=False), feat_pipe__num__scaler=StandardScaler(copy=True, with_mean=True, with_std=True) \n",
      "[CV]  classifier=LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=1,\n",
      "                   max_iter=1000, multi_class='warn', n_jobs=10,\n",
      "                   penalty='elasticnet', random_state=42, solver='saga',\n",
      "                   tol=0.0001, verbose=0, warm_start=False), classifier__l1_ratio=1, feat_pipe__cat__cat_encoder_1=FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
      "                    func=<function from_cat_to_str at 0x000001E59BA580D8>,\n",
      "                    inv_kw_args=None, inverse_func=None, kw_args=None,\n",
      "                    pass_y='deprecated', validate=False), feat_pipe__cat__cat_encoder_2=OneHotEncoder(categorical_features=None, categories='auto', drop=None,\n",
      "              dtype=<class 'numpy.uint8'>, handle_unknown='ignore',\n",
      "              n_values=None, sparse=False), feat_pipe__num__scaler=StandardScaler(copy=True, with_mean=True, with_std=True), total=   7.8s\n",
      "[CV] classifier=LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=1,\n",
      "                   max_iter=1000, multi_class='warn', n_jobs=10,\n",
      "                   penalty='elasticnet', random_state=42, solver='saga',\n",
      "                   tol=0.0001, verbose=0, warm_start=False), classifier__l1_ratio=1, feat_pipe__cat__cat_encoder_1=FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
      "                    func=<function from_cat_to_str at 0x000001E59BA580D8>,\n",
      "                    inv_kw_args=None, inverse_func=None, kw_args=None,\n",
      "                    pass_y='deprecated', validate=False), feat_pipe__cat__cat_encoder_2=OneHotEncoder(categorical_features=None, categories='auto', drop=None,\n",
      "              dtype=<class 'numpy.uint8'>, handle_unknown='ignore',\n",
      "              n_values=None, sparse=False), feat_pipe__num__scaler=StandardScaler(copy=True, with_mean=True, with_std=True) \n",
      "[CV]  classifier=LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=1,\n",
      "                   max_iter=1000, multi_class='warn', n_jobs=10,\n",
      "                   penalty='elasticnet', random_state=42, solver='saga',\n",
      "                   tol=0.0001, verbose=0, warm_start=False), classifier__l1_ratio=1, feat_pipe__cat__cat_encoder_1=FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
      "                    func=<function from_cat_to_str at 0x000001E59BA580D8>,\n",
      "                    inv_kw_args=None, inverse_func=None, kw_args=None,\n",
      "                    pass_y='deprecated', validate=False), feat_pipe__cat__cat_encoder_2=OneHotEncoder(categorical_features=None, categories='auto', drop=None,\n",
      "              dtype=<class 'numpy.uint8'>, handle_unknown='ignore',\n",
      "              n_values=None, sparse=False), feat_pipe__num__scaler=StandardScaler(copy=True, with_mean=True, with_std=True), total=   8.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:  2.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('feat_pipe',\n",
       "                                        ColumnTransformer(n_jobs=None,\n",
       "                                                          remainder='drop',\n",
       "                                                          sparse_threshold=0.3,\n",
       "                                                          transformer_weights=None,\n",
       "                                                          transformers=[('cat',\n",
       "                                                                         Pipeline(memory=None,\n",
       "                                                                                  steps=[('cat_imputer',\n",
       "                                                                                          SimpleImputer(add_indicator=False,\n",
       "                                                                                                        cop...\n",
       "                          'feat_pipe__cat__cat_encoder_2': [OneHotEncoder(categorical_features=None,\n",
       "                                                                          categories='auto',\n",
       "                                                                          drop=None,\n",
       "                                                                          dtype=<class 'numpy.uint8'>,\n",
       "                                                                          handle_unknown='ignore',\n",
       "                                                                          n_values=None,\n",
       "                                                                          sparse=False)],\n",
       "                          'feat_pipe__num__scaler': [StandardScaler(copy=True,\n",
       "                                                                    with_mean=True,\n",
       "                                                                    with_std=True)]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring=make_scorer(ks_stat, needs_proba=True), verbose=2)"
      ]
     },
     "execution_count": 601,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = [\n",
    "# #     Logistic regression\n",
    "    {\n",
    "        'feat_pipe__num__scaler': [StandardScaler()],\n",
    "        'feat_pipe__cat__cat_encoder_1': [from_cat_to_str_transformer],\n",
    "        'feat_pipe__cat__cat_encoder_2': [OneHotEncoder(sparse=False, categories='auto', handle_unknown='ignore', dtype=np.uint8)],\n",
    "        'classifier': [LogisticRegression(random_state=random_state_global, max_iter=1000, penalty='elasticnet',\n",
    "                                          solver='saga',class_weight='balanced', n_jobs=10)],\n",
    "        'classifier__l1_ratio': [0, 0.5, 1]\n",
    "    }\n",
    ",\n",
    "#     Random Forest\n",
    "\n",
    "#      {\n",
    "#          'feat_pipe__num__scaler': [None],\n",
    "#          'feat_pipe__cat__cat_encoder_1': [None],\n",
    "#          'feat_pipe__cat__cat_encoder_2': [OneHotEncoder(sparse=False, categories='auto', handle_unknown='ignore', dtype=np.uint8)],\n",
    "#          'classifier': [RandomForestClassifier(n_jobs=10, n_estimators=500)],\n",
    "#          'classifier__class_weight': ['balanced', 'balanced_subsample']\n",
    "#     }\n",
    "]\n",
    "    \n",
    "param_grid\n",
    "gs = GridSearchCV(cv=kf, param_grid=param_grid, estimator=clf, n_jobs=1, scoring=ks_scorer, verbose=2, return_train_score=True)\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T05:53:20.932185Z",
     "start_time": "2019-08-14T05:53:20.927181Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "                    fit_intercept=True, intercept_scaling=1, l1_ratio=1,\n",
       "                    max_iter=1000, multi_class='warn', n_jobs=10,\n",
       "                    penalty='elasticnet', random_state=42, solver='saga',\n",
       "                    tol=0.0001, verbose=0, warm_start=False),\n",
       " 'classifier__l1_ratio': 1,\n",
       " 'feat_pipe__cat__cat_encoder_1': FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
       "                     func=<function from_cat_to_str at 0x000001E59BA580D8>,\n",
       "                     inv_kw_args=None, inverse_func=None, kw_args=None,\n",
       "                     pass_y='deprecated', validate=False),\n",
       " 'feat_pipe__cat__cat_encoder_2': OneHotEncoder(categorical_features=None, categories='auto', drop=None,\n",
       "               dtype=<class 'numpy.uint8'>, handle_unknown='ignore',\n",
       "               n_values=None, sparse=False),\n",
       " 'feat_pipe__num__scaler': StandardScaler(copy=True, with_mean=True, with_std=True)}"
      ]
     },
     "execution_count": 641,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T05:54:31.731672Z",
     "start_time": "2019-08-14T05:54:31.703650Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('feat_pipe',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('cat',\n",
       "                                                  Pipeline(memory=None,\n",
       "                                                           steps=[('cat_imputer',\n",
       "                                                                   SimpleImputer(add_indicator=False,\n",
       "                                                                                 copy=True,\n",
       "                                                                                 fill_value='cat_missing',\n",
       "                                                                                 missing_values=nan,\n",
       "                                                                                 strategy='constant',\n",
       "                                                                                 verbose=0)),\n",
       "                                                                  ('cat_encoder_1',\n",
       "                                                                   FunctionTransfo...\n",
       "                                                   'cons_price_idx',\n",
       "                                                   'cons_conf_idx', 'euribor3m',\n",
       "                                                   'nr_employed'])],\n",
       "                                   verbose=False)),\n",
       "                ('classifier',\n",
       "                 LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=1, max_iter=1000,\n",
       "                                    multi_class='warn', n_jobs=10,\n",
       "                                    penalty='elasticnet', random_state=42,\n",
       "                                    solver='saga', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 649,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.estimator.set_params(**gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T05:55:30.788397Z",
     "start_time": "2019-08-14T05:55:30.775394Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 5.323034  , 13.75394874,  7.99674449]),\n",
       " 'std_fit_time': array([0.47139887, 2.64847781, 1.68242016]),\n",
       " 'mean_score_time': array([0.14433866, 0.14370584, 0.14295053]),\n",
       " 'std_score_time': array([0.00264282, 0.00188425, 0.00360369]),\n",
       " 'param_classifier': masked_array(data=[LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "                    fit_intercept=True, intercept_scaling=1, l1_ratio=1,\n",
       "                    max_iter=1000, multi_class='warn', n_jobs=10,\n",
       "                    penalty='elasticnet', random_state=42, solver='saga',\n",
       "                    tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "                    fit_intercept=True, intercept_scaling=1, l1_ratio=1,\n",
       "                    max_iter=1000, multi_class='warn', n_jobs=10,\n",
       "                    penalty='elasticnet', random_state=42, solver='saga',\n",
       "                    tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "                    fit_intercept=True, intercept_scaling=1, l1_ratio=1,\n",
       "                    max_iter=1000, multi_class='warn', n_jobs=10,\n",
       "                    penalty='elasticnet', random_state=42, solver='saga',\n",
       "                    tol=0.0001, verbose=0, warm_start=False)],\n",
       "              mask=[False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__l1_ratio': masked_array(data=[0, 0.5, 1],\n",
       "              mask=[False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_feat_pipe__cat__cat_encoder_1': masked_array(data=[FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
       "                     func=<function from_cat_to_str at 0x000001E59BA580D8>,\n",
       "                     inv_kw_args=None, inverse_func=None, kw_args=None,\n",
       "                     pass_y='deprecated', validate=False),\n",
       "                    FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
       "                     func=<function from_cat_to_str at 0x000001E59BA580D8>,\n",
       "                     inv_kw_args=None, inverse_func=None, kw_args=None,\n",
       "                     pass_y='deprecated', validate=False),\n",
       "                    FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
       "                     func=<function from_cat_to_str at 0x000001E59BA580D8>,\n",
       "                     inv_kw_args=None, inverse_func=None, kw_args=None,\n",
       "                     pass_y='deprecated', validate=False)],\n",
       "              mask=[False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_feat_pipe__cat__cat_encoder_2': masked_array(data=[OneHotEncoder(categorical_features=None, categories='auto', drop=None,\n",
       "               dtype=<class 'numpy.uint8'>, handle_unknown='ignore',\n",
       "               n_values=None, sparse=False),\n",
       "                    OneHotEncoder(categorical_features=None, categories='auto', drop=None,\n",
       "               dtype=<class 'numpy.uint8'>, handle_unknown='ignore',\n",
       "               n_values=None, sparse=False),\n",
       "                    OneHotEncoder(categorical_features=None, categories='auto', drop=None,\n",
       "               dtype=<class 'numpy.uint8'>, handle_unknown='ignore',\n",
       "               n_values=None, sparse=False)],\n",
       "              mask=[False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_feat_pipe__num__scaler': masked_array(data=[StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       "                    StandardScaler(copy=True, with_mean=True, with_std=True)],\n",
       "              mask=[False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'classifier': LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "                      fit_intercept=True, intercept_scaling=1, l1_ratio=1,\n",
       "                      max_iter=1000, multi_class='warn', n_jobs=10,\n",
       "                      penalty='elasticnet', random_state=42, solver='saga',\n",
       "                      tol=0.0001, verbose=0, warm_start=False),\n",
       "   'classifier__l1_ratio': 0,\n",
       "   'feat_pipe__cat__cat_encoder_1': FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
       "                       func=<function from_cat_to_str at 0x000001E59BA580D8>,\n",
       "                       inv_kw_args=None, inverse_func=None, kw_args=None,\n",
       "                       pass_y='deprecated', validate=False),\n",
       "   'feat_pipe__cat__cat_encoder_2': OneHotEncoder(categorical_features=None, categories='auto', drop=None,\n",
       "                 dtype=<class 'numpy.uint8'>, handle_unknown='ignore',\n",
       "                 n_values=None, sparse=False),\n",
       "   'feat_pipe__num__scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
       "  {'classifier': LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "                      fit_intercept=True, intercept_scaling=1, l1_ratio=1,\n",
       "                      max_iter=1000, multi_class='warn', n_jobs=10,\n",
       "                      penalty='elasticnet', random_state=42, solver='saga',\n",
       "                      tol=0.0001, verbose=0, warm_start=False),\n",
       "   'classifier__l1_ratio': 0.5,\n",
       "   'feat_pipe__cat__cat_encoder_1': FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
       "                       func=<function from_cat_to_str at 0x000001E59BA580D8>,\n",
       "                       inv_kw_args=None, inverse_func=None, kw_args=None,\n",
       "                       pass_y='deprecated', validate=False),\n",
       "   'feat_pipe__cat__cat_encoder_2': OneHotEncoder(categorical_features=None, categories='auto', drop=None,\n",
       "                 dtype=<class 'numpy.uint8'>, handle_unknown='ignore',\n",
       "                 n_values=None, sparse=False),\n",
       "   'feat_pipe__num__scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
       "  {'classifier': LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "                      fit_intercept=True, intercept_scaling=1, l1_ratio=1,\n",
       "                      max_iter=1000, multi_class='warn', n_jobs=10,\n",
       "                      penalty='elasticnet', random_state=42, solver='saga',\n",
       "                      tol=0.0001, verbose=0, warm_start=False),\n",
       "   'classifier__l1_ratio': 1,\n",
       "   'feat_pipe__cat__cat_encoder_1': FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
       "                       func=<function from_cat_to_str at 0x000001E59BA580D8>,\n",
       "                       inv_kw_args=None, inverse_func=None, kw_args=None,\n",
       "                       pass_y='deprecated', validate=False),\n",
       "   'feat_pipe__cat__cat_encoder_2': OneHotEncoder(categorical_features=None, categories='auto', drop=None,\n",
       "                 dtype=<class 'numpy.uint8'>, handle_unknown='ignore',\n",
       "                 n_values=None, sparse=False),\n",
       "   'feat_pipe__num__scaler': StandardScaler(copy=True, with_mean=True, with_std=True)}],\n",
       " 'split0_test_score': array([0.77204496, 0.77272884, 0.77255787]),\n",
       " 'split1_test_score': array([0.75925871, 0.76009533, 0.75958242]),\n",
       " 'split2_test_score': array([0.76361277, 0.76360147, 0.76377244]),\n",
       " 'split3_test_score': array([0.76146308, 0.76112114, 0.76212873]),\n",
       " 'split4_test_score': array([0.75241993, 0.75207799, 0.75257267]),\n",
       " 'mean_test_score': array([0.76175989, 0.76192495, 0.76212283]),\n",
       " 'std_test_score': array([0.00636859, 0.00664065, 0.00646947]),\n",
       " 'rank_test_score': array([3, 2, 1]),\n",
       " 'split0_train_score': array([0.76020925, 0.76026111, 0.76035069]),\n",
       " 'split1_train_score': array([0.76266616, 0.76262341, 0.76219599]),\n",
       " 'split2_train_score': array([0.76199249, 0.76208536, 0.76202894]),\n",
       " 'split3_train_score': array([0.76277442, 0.76310725, 0.76306451]),\n",
       " 'split4_train_score': array([0.76682301, 0.76665204, 0.76715128]),\n",
       " 'mean_train_score': array([0.76289307, 0.76294583, 0.76295828]),\n",
       " 'std_train_score': array([0.00216905, 0.00208874, 0.00227318])}"
      ]
     },
     "execution_count": 655,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T05:55:16.364061Z",
     "start_time": "2019-08-14T05:55:16.102826Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7626890325093346"
      ]
     },
     "execution_count": 652,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ks_stat(y_train, gs.predict_proba(X_train)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T05:55:22.678419Z",
     "start_time": "2019-08-14T05:55:22.495699Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7523691457836169"
      ]
     },
     "execution_count": 654,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ks_stat(y_test, gs.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T05:44:52.685060Z",
     "start_time": "2019-08-14T05:44:52.682057Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T05:55:56.344934Z",
     "start_time": "2019-08-14T05:55:55.935554Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([17669.,  3783.,  1834.,  1231.,  1000.,  1038.,  1129.,  1151.,\n",
       "         1353.,  2762.]),\n",
       " array([0.00241242, 0.10217118, 0.20192994, 0.3016887 , 0.40144745,\n",
       "        0.50120621, 0.60096497, 0.70072373, 0.80048248, 0.90024124,\n",
       "        1.        ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 656,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(gs.predict_proba(X_train)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T05:57:06.148027Z",
     "start_time": "2019-08-14T05:57:05.743637Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3295., 3295., 3295., 3295., 3295., 3295., 3295., 3295., 3295.,\n",
       "        3295.]),\n",
       " array([ 0. ,  9.9, 19.8, 29.7, 39.6, 49.5, 59.4, 69.3, 79.2, 89.1, 99. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 660,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "binner = KBinsDiscretizer(n_bins=100, encode='ordinal', strategy='quantile')\n",
    "plt.hist(binner.fit_transform(gs.predict_proba(X_train)[:,1].reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T05:57:10.317327Z",
     "start_time": "2019-08-14T05:57:09.911527Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([17669.,  3783.,  1834.,  1231.,  1000.,  1037.,  1130.,  1151.,\n",
       "         1353.,  2762.]),\n",
       " array([ 0. ,  9.9, 19.8, 29.7, 39.6, 49.5, 59.4, 69.3, 79.2, 89.1, 99. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 661,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "binner = KBinsDiscretizer(n_bins=100, encode='ordinal', strategy='uniform')\n",
    "plt.hist(binner.fit_transform(gs.predict_proba(X_train)[:,1].reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T06:00:56.531498Z",
     "start_time": "2019-08-14T06:00:55.783360Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([12805.,  5955.,  2847.,  1866.,  1447.,  1317.,  1426.,  1397.,\n",
       "         1524.,  2366.]),\n",
       " array([0. , 0.9, 1.8, 2.7, 3.6, 4.5, 5.4, 6.3, 7.2, 8.1, 9. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 680,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "binner = KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='kmeans')\n",
    "plt.hist(binner.fit_transform(gs.predict_proba(X_train)[:,1].reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T06:01:20.353005Z",
     "start_time": "2019-08-14T06:01:19.751451Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       ...,\n",
       "       [9.],\n",
       "       [1.],\n",
       "       [3.]])"
      ]
     },
     "execution_count": 683,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binner.fit_transform(gs.predict_proba(X_train)[:,1].reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-14T06:01:34.566Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.barplot(x=gs.predict_proba(X_train)[:,1],\n",
    "            y=binner.fit_transform(gs.predict_proba(X_train)[:,1].reshape(-1,1)).ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T05:58:37.524008Z",
     "start_time": "2019-08-14T05:58:36.718792Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e59e7e0888>"
      ]
     },
     "execution_count": 667,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(gs.predict_proba(X_train)[:,1].reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T05:44:56.034420Z",
     "start_time": "2019-08-14T05:44:56.021408Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 5.323034  , 13.75394874,  7.99674449]),\n",
       " 'std_fit_time': array([0.47139887, 2.64847781, 1.68242016]),\n",
       " 'mean_score_time': array([0.14433866, 0.14370584, 0.14295053]),\n",
       " 'std_score_time': array([0.00264282, 0.00188425, 0.00360369]),\n",
       " 'param_classifier': masked_array(data=[LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "                    fit_intercept=True, intercept_scaling=1, l1_ratio=1,\n",
       "                    max_iter=1000, multi_class='warn', n_jobs=10,\n",
       "                    penalty='elasticnet', random_state=42, solver='saga',\n",
       "                    tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "                    fit_intercept=True, intercept_scaling=1, l1_ratio=1,\n",
       "                    max_iter=1000, multi_class='warn', n_jobs=10,\n",
       "                    penalty='elasticnet', random_state=42, solver='saga',\n",
       "                    tol=0.0001, verbose=0, warm_start=False),\n",
       "                    LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "                    fit_intercept=True, intercept_scaling=1, l1_ratio=1,\n",
       "                    max_iter=1000, multi_class='warn', n_jobs=10,\n",
       "                    penalty='elasticnet', random_state=42, solver='saga',\n",
       "                    tol=0.0001, verbose=0, warm_start=False)],\n",
       "              mask=[False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__l1_ratio': masked_array(data=[0, 0.5, 1],\n",
       "              mask=[False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_feat_pipe__cat__cat_encoder_1': masked_array(data=[FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
       "                     func=<function from_cat_to_str at 0x000001E59BA580D8>,\n",
       "                     inv_kw_args=None, inverse_func=None, kw_args=None,\n",
       "                     pass_y='deprecated', validate=False),\n",
       "                    FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
       "                     func=<function from_cat_to_str at 0x000001E59BA580D8>,\n",
       "                     inv_kw_args=None, inverse_func=None, kw_args=None,\n",
       "                     pass_y='deprecated', validate=False),\n",
       "                    FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
       "                     func=<function from_cat_to_str at 0x000001E59BA580D8>,\n",
       "                     inv_kw_args=None, inverse_func=None, kw_args=None,\n",
       "                     pass_y='deprecated', validate=False)],\n",
       "              mask=[False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_feat_pipe__cat__cat_encoder_2': masked_array(data=[OneHotEncoder(categorical_features=None, categories='auto', drop=None,\n",
       "               dtype=<class 'numpy.uint8'>, handle_unknown='ignore',\n",
       "               n_values=None, sparse=False),\n",
       "                    OneHotEncoder(categorical_features=None, categories='auto', drop=None,\n",
       "               dtype=<class 'numpy.uint8'>, handle_unknown='ignore',\n",
       "               n_values=None, sparse=False),\n",
       "                    OneHotEncoder(categorical_features=None, categories='auto', drop=None,\n",
       "               dtype=<class 'numpy.uint8'>, handle_unknown='ignore',\n",
       "               n_values=None, sparse=False)],\n",
       "              mask=[False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_feat_pipe__num__scaler': masked_array(data=[StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       "                    StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       "                    StandardScaler(copy=True, with_mean=True, with_std=True)],\n",
       "              mask=[False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'classifier': LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "                      fit_intercept=True, intercept_scaling=1, l1_ratio=1,\n",
       "                      max_iter=1000, multi_class='warn', n_jobs=10,\n",
       "                      penalty='elasticnet', random_state=42, solver='saga',\n",
       "                      tol=0.0001, verbose=0, warm_start=False),\n",
       "   'classifier__l1_ratio': 0,\n",
       "   'feat_pipe__cat__cat_encoder_1': FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
       "                       func=<function from_cat_to_str at 0x000001E59BA580D8>,\n",
       "                       inv_kw_args=None, inverse_func=None, kw_args=None,\n",
       "                       pass_y='deprecated', validate=False),\n",
       "   'feat_pipe__cat__cat_encoder_2': OneHotEncoder(categorical_features=None, categories='auto', drop=None,\n",
       "                 dtype=<class 'numpy.uint8'>, handle_unknown='ignore',\n",
       "                 n_values=None, sparse=False),\n",
       "   'feat_pipe__num__scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
       "  {'classifier': LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "                      fit_intercept=True, intercept_scaling=1, l1_ratio=1,\n",
       "                      max_iter=1000, multi_class='warn', n_jobs=10,\n",
       "                      penalty='elasticnet', random_state=42, solver='saga',\n",
       "                      tol=0.0001, verbose=0, warm_start=False),\n",
       "   'classifier__l1_ratio': 0.5,\n",
       "   'feat_pipe__cat__cat_encoder_1': FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
       "                       func=<function from_cat_to_str at 0x000001E59BA580D8>,\n",
       "                       inv_kw_args=None, inverse_func=None, kw_args=None,\n",
       "                       pass_y='deprecated', validate=False),\n",
       "   'feat_pipe__cat__cat_encoder_2': OneHotEncoder(categorical_features=None, categories='auto', drop=None,\n",
       "                 dtype=<class 'numpy.uint8'>, handle_unknown='ignore',\n",
       "                 n_values=None, sparse=False),\n",
       "   'feat_pipe__num__scaler': StandardScaler(copy=True, with_mean=True, with_std=True)},\n",
       "  {'classifier': LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "                      fit_intercept=True, intercept_scaling=1, l1_ratio=1,\n",
       "                      max_iter=1000, multi_class='warn', n_jobs=10,\n",
       "                      penalty='elasticnet', random_state=42, solver='saga',\n",
       "                      tol=0.0001, verbose=0, warm_start=False),\n",
       "   'classifier__l1_ratio': 1,\n",
       "   'feat_pipe__cat__cat_encoder_1': FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
       "                       func=<function from_cat_to_str at 0x000001E59BA580D8>,\n",
       "                       inv_kw_args=None, inverse_func=None, kw_args=None,\n",
       "                       pass_y='deprecated', validate=False),\n",
       "   'feat_pipe__cat__cat_encoder_2': OneHotEncoder(categorical_features=None, categories='auto', drop=None,\n",
       "                 dtype=<class 'numpy.uint8'>, handle_unknown='ignore',\n",
       "                 n_values=None, sparse=False),\n",
       "   'feat_pipe__num__scaler': StandardScaler(copy=True, with_mean=True, with_std=True)}],\n",
       " 'split0_test_score': array([0.77204496, 0.77272884, 0.77255787]),\n",
       " 'split1_test_score': array([0.75925871, 0.76009533, 0.75958242]),\n",
       " 'split2_test_score': array([0.76361277, 0.76360147, 0.76377244]),\n",
       " 'split3_test_score': array([0.76146308, 0.76112114, 0.76212873]),\n",
       " 'split4_test_score': array([0.75241993, 0.75207799, 0.75257267]),\n",
       " 'mean_test_score': array([0.76175989, 0.76192495, 0.76212283]),\n",
       " 'std_test_score': array([0.00636859, 0.00664065, 0.00646947]),\n",
       " 'rank_test_score': array([3, 2, 1]),\n",
       " 'split0_train_score': array([0.76020925, 0.76026111, 0.76035069]),\n",
       " 'split1_train_score': array([0.76266616, 0.76262341, 0.76219599]),\n",
       " 'split2_train_score': array([0.76199249, 0.76208536, 0.76202894]),\n",
       " 'split3_train_score': array([0.76277442, 0.76310725, 0.76306451]),\n",
       " 'split4_train_score': array([0.76682301, 0.76665204, 0.76715128]),\n",
       " 'mean_train_score': array([0.76289307, 0.76294583, 0.76295828]),\n",
       " 'std_train_score': array([0.00216905, 0.00208874, 0.00227318])}"
      ]
     },
     "execution_count": 609,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T05:05:49.709709Z",
     "start_time": "2019-08-14T05:05:49.705714Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': RandomForestClassifier(bootstrap=True, class_weight='balanced_subsample',\n",
       "                        criterion='gini', max_depth=None, max_features='auto',\n",
       "                        max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                        min_impurity_split=None, min_samples_leaf=1,\n",
       "                        min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                        n_estimators=500, n_jobs=10, oob_score=False,\n",
       "                        random_state=None, verbose=0, warm_start=False),\n",
       " 'classifier__class_weight': 'balanced_subsample',\n",
       " 'feat_pipe__cat__cat_encoder_1': None,\n",
       " 'feat_pipe__cat__cat_encoder_2': OneHotEncoder(categorical_features=None, categories='auto', drop=None,\n",
       "               dtype=<class 'numpy.uint8'>, handle_unknown='ignore',\n",
       "               n_values=None, sparse=False),\n",
       " 'feat_pipe__num__scaler': None}"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sklearn_novo_2]",
   "language": "python",
   "name": "conda-env-sklearn_novo_2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
